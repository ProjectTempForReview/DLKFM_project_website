## Abstract

 Those images captured by different sensors, or captured by the same sensor under different conditions, have various textures for the same scene. In this paper, we propose a solution to precisely align those multimodality image pairs. Inspired by the inverse compositional Lucas-Kanade algorithm on regular images, we construct a deep Lucas-Kanade feature map (DLKFM). DLKFM distinguishes invariant features from changing color textures, which allows inverse compositional Lucas-Kanade algorithm accurately finding homography parameters on those challenge cases. Technically, our solution is a two-phase optimization pipeline. The first phase optimization is the training of a Siamese network. The second phase is the iterative inverse compositional updating on feature maps during testing. We design a loss function to help the learned DLKFM achieve two goals: 1. keeps brightness consistency, 2. helps the convergence of second phase optimization. Proposed method has been tested on three different datasets, including a regular image alignment dataset MSCOCO, a cross season image dataset, and a multimodality dataset with Google Map and Google Satellite. The strong performance versus several baselines indicates the widely potential usage in the field of general image alignment.


![Alt Text](https://github.com/ProjectTempForReview/Deep-Homography-via-Lifting-Lucas-Kanade-Method/demo.gif)
